<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>SSL with ResNet-101 + MoCo · Samarth Agarwal</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="./styles/main.css">
</head>

<body>
  <div class="page">
    <header class="site-header">
      <div class="brand">Samarth Agarwal</div>
      <nav class="nav" aria-label="Primary">
        <a href="./index.html#about">About</a>
        <a href="./index.html#projects">Projects</a>
        <a href="./index.html#experience">Experience</a>
        <a href="./index.html#contact">Contact</a>
      </nav>
      <a class="button ghost" href="https://github.com/Samarth26" target="_blank" rel="noopener">GitHub</a>
    </header>

    <main>
      <article class="blog-post">
        <div class="blog-post__header">
          <a href="./index.html#projects" class="back-link">← Back to projects</a>
          <h1>Self-Supervised Learning with ResNet-101 + MoCo</h1>
          <div class="blog-meta">
            <span class="pill">Self-Supervised Learning</span>
            <span class="pill">MoCo · SimCLR · BYOL</span>
            <span class="pill">ResNet-101</span>
            <span class="pill">Linear Probe + kNN</span>
          </div>
        </div>

        <div class="blog-post__content">
          <section>
            <h2>Overview</h2>
            <p>
              This project studies self-supervised representation learning for image classification using a
              <strong>ResNet-101 encoder</strong> under realistic compute constraints. I implemented and compared three
              widely-used SSL frameworks—<strong>SimCLR</strong>, <strong>MoCo</strong>, and <strong>BYOL</strong>—under a unified
              training and evaluation setup, and measured representation quality using <strong>linear probing</strong> and
              <strong>k-nearest neighbors (kNN)</strong> across multiple datasets. :contentReference[oaicite:1]{index=1}
            </p>
            <p>
              A key finding was that representation quality improves rapidly early in training and then
              <strong>saturates around ~50 epochs</strong>, with diminishing returns beyond that point. :contentReference[oaicite:2]{index=2}
            </p>
          </section>

          <section>
            <h2>Motivation</h2>
            <p>
              Image classification typically relies on large labeled datasets, which can be expensive or infeasible to obtain.
              Self-supervised learning addresses this by learning useful visual representations directly from unlabeled images.
              However, many recent SSL methods require very large backbones, huge datasets, and long training schedules.
              In this work, I focused on a strong but tractable backbone—<strong>ResNet-101</strong>—and explored practical
              SSL training under limited GPU resources and a short development timeline. :contentReference[oaicite:3]{index=3}
            </p>
          </section>

          <section>
            <h2>Methodology</h2>

            <h3>Two-stage SSL pipeline</h3>
            <p>
              The training follows a standard two-stage SSL workflow:
              (1) pretrain an encoder on unlabeled data using an SSL objective, then
              (2) freeze the encoder and evaluate learned representations using linear probing or kNN classification. :contentReference[oaicite:4]{index=4}
            </p>

            <h3>Augmentations</h3>
            <p>
              All methods share a SimCLR-style augmentation pipeline. Images are resized to <strong>96×96</strong>, and two
              independent “global views” are created using random resized crops, horizontal flip, color jitter, grayscale conversion,
              and Gaussian blur. :contentReference[oaicite:5]{index=5}
            </p>
            <p>
              I also explored an optional <strong>local-crop augmentation</strong> to emphasize fine-grained structure and
              encourage multi-scale consistency; this was implemented with GPU-accelerated Kornia to avoid CPU bottlenecks. :contentReference[oaicite:6]{index=6}
            </p>

            <h3>Architecture</h3>
            <p>
              The backbone is <strong>ResNet-101</strong> with the classification head removed. A 2-layer MLP projection head
              maps encoder outputs into the embedding space used by the SSL objective; projection dimensionality is treated as a tunable
              hyperparameter shared across methods. :contentReference[oaicite:7]{index=7}
            </p>

            <h3>SSL objectives compared</h3>
            <ul>
              <li>
                <strong>SimCLR:</strong> contrastive learning using in-batch negatives; performance is sensitive to batch size
                because negatives come from the minibatch. :contentReference[oaicite:8]{index=8}
              </li>
              <li>
                <strong>MoCo:</strong> contrastive learning with a momentum-updated key encoder and a queue of negatives,
                reducing dependence on large batch sizes. :contentReference[oaicite:9]{index=9}
              </li>
              <li>
                <strong>BYOL:</strong> bootstrap learning without explicit negatives; uses online/target networks with EMA updates
                and a predictor head to avoid collapse. :contentReference[oaicite:10]{index=10}
              </li>
            </ul>

            <h3>Training & evaluation</h3>
            <p>
              SimCLR and MoCo were trained with Adam + cosine annealing; BYOL used SGD with momentum. Mixed precision was enabled.
              Performance was evaluated using both linear probing and kNN to measure representation quality without fine-tuning the backbone. :contentReference[oaicite:11]{index=11}
            </p>
          </section>

          <section>
            <h2>Experimental Journey</h2>
            <p>
              The project evolved iteratively. I started with <strong>ResNet-50</strong> and focused on kNN evaluation on the
              fine-grained CUB-200 dataset. Early experiments used SimCLR and BYOL; adding ~200k iNaturalist images improved
              visual diversity and gave modest gains. Introducing local crops improved kNN performance further (≈15% on CUB-200),
              motivating deeper scaling and more stable objectives. :contentReference[oaicite:12]{index=12}
            </p>

            <p>
              Next, I transitioned to <strong>MoCo</strong> after observing better stability. I scaled from ResNet-50 → Wide ResNet-50
              → <strong>ResNet-101</strong>, with ResNet-101 achieving the strongest performance. To improve generalization, I expanded
              pretraining with ~600k CC12M images, which helped particularly on Mini-ImageNet and SUN. :contentReference[oaicite:13]{index=13}
            </p>
          </section>

          <section>
            <h2>Training Dynamics</h2>
            <p>
              Different SSL methods showed noticeably different optimization behavior:
            </p>
            <ul>
              <li>
                <strong>SimCLR:</strong> loss dropped quickly and saturated early (~0.12), then oscillated without corresponding
                downstream gains. :contentReference[oaicite:14]{index=14}
              </li>
              <li>
                <strong>BYOL:</strong> exhibited less stable training, with loss not clearly stabilizing across runs. :contentReference[oaicite:15]{index=15}
              </li>
              <li>
                <strong>MoCo:</strong> showed the most consistent behavior—loss fell rapidly then gradually decreased, though downstream
                improvements still saturated even as loss kept dropping. :contentReference[oaicite:16]{index=16}
              </li>
            </ul>
            <p>
              The big takeaway: <strong>loss convergence isn’t a guarantee of continued representation gains</strong>—you need to track
              downstream metrics (kNN/linear probe) to detect diminishing returns. :contentReference[oaicite:17]{index=17}
            </p>
          </section>

          <section>
            <h2>Results</h2>

            <h3>Early improvement, then saturation</h3>
            <p>
              Across datasets, both kNN and linear probing improved quickly in the first 20–40 epochs and stabilized around
              <strong>~50 epochs</strong>. kNN used <strong>k=20</strong> and was evaluated every 5 epochs; linear probing was evaluated every 10 epochs. :contentReference[oaicite:18]{index=18}
            </p>

            <h3>Final configuration (Leaderboard setup)</h3>
            <p>
              For the final submission, I pretrained <strong>ResNet-101</strong> for <strong>100 epochs</strong> using the expanded pretraining
              dataset. I then froze the encoder and trained a linear probe for <strong>30 epochs</strong>.
              A small grid search found the best linear-probe hyperparameters at <strong>LR = 1e-2</strong> and <strong>weight decay = 0</strong>.
              Compared to defaults, tuning and longer probe training improved results by ~5–15% across datasets. :contentReference[oaicite:19]{index=19}
            </p>

            <table class="results-table">
              <tr>
                <th>Dataset (Leaderboard Part)</th>
                <th>Public</th>
                <th>Private</th>
              </tr>
              <tr>
                <td>Part 1 (Dataset 1)</td>
                <td>34.46%</td>
                <td>31.26%</td>
              </tr>
              <tr>
                <td>Part 2 (Dataset 2)</td>
                <td>59.93%</td>
                <td>62.05%</td>
              </tr>
              <tr>
                <td>Part 3 (Dataset 3)</td>
                <td>33.58%</td>
                <td>33.24%</td>
              </tr>
            </table>
            <p>
              <strong>Best-performing approach:</strong> momentum-based contrastive learning (MoCo) + backbone scaling to ResNet-101,
              paired with data diversity/scale improvements. :contentReference[oaicite:20]{index=20}
            </p>
          </section>

          <section>
            <h2>Key Takeaways</h2>
            <ul>
              <li><strong>MoCo was the most stable</strong> under constrained compute compared to SimCLR and BYOL. :contentReference[oaicite:21]{index=21}</li>
              <li><strong>Data diversity and scale helped</strong>: adding iNaturalist and CC12M improved downstream performance. :contentReference[oaicite:22]{index=22}</li>
              <li><strong>Multi-scale augmentations matter</strong>: local crops improved representation quality in early stages. :contentReference[oaicite:23]{index=23}</li>
              <li><strong>Stop at the knee</strong>: performance saturates around ~50 epochs—track downstream metrics, not just loss. :contentReference[oaicite:24]{index=24}</li>
              <li><strong>Linear-probe tuning is underrated</strong>: small grid search + longer probe improved results across datasets. :contentReference[oaicite:25]{index=25}</li>
            </ul>
          </section>

          <section>
            <h2>Links</h2>
            <p>
              <strong>Repo:</strong> <a href="https://github.com/Samarth26/Image-SSL" target="_blank" rel="noopener">GitHub</a><br>
              <strong>Report:</strong> <a href="./ssl-report.pdf" target="_blank" rel="noopener">PDF</a>
            </p>
          </section>
        </div>

        <div class="blog-nav">
          <a href="./blog-freight.html" class="blog-nav__link">← Previous: Agentic OCR & Email Automation</a>
          <a href="./index.html#projects" class="blog-nav__link">All Projects</a>
          <a href="./blog-recommender.html" class="blog-nav__link">Next: Movie Recommender →</a>
        </div>
      </article>
    </main>

    <footer class="site-footer">
      <span>© <span id="year"></span> Samarth Agarwal</span>
      <div class="footer__links">
        <a href="./index.html#top">Back to home</a>
      </div>
    </footer>
  </div>

  <script src="./scripts/main.js"></script>
  <script>
    // If your main.js already sets this, you can remove this block.
    const y = document.getElementById("year");
    if (y) y.textContent = new Date().getFullYear();
  </script>
</body>
</html>

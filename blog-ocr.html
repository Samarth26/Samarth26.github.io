<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Agentic OCR & Email Automation · Samarth Agarwal</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="./styles/main.css">
</head>

<body>
  <div class="page">
    <header class="site-header">
      <div class="brand">Samarth Agarwal</div>
      <nav class="nav" aria-label="Primary">
        <a href="./index.html#about">About</a>
        <a href="./index.html#projects">Projects</a>
        <a href="./index.html#experience">Experience</a>
        <a href="./index.html#contact">Contact</a>
      </nav>
      <a class="button ghost" href="https://github.com/Samarth26" target="_blank" rel="noopener">GitHub</a>
    </header>

    <main>
      <article class="blog-post">
        <div class="blog-post__header">
          <a href="./index.html#projects" class="back-link">← Back to projects</a>
          <h1>Agentic OCR & Email Automation</h1>
          <div class="blog-meta">
            <span class="pill">LangChain · LLMs</span>
            <span class="pill">OCR</span>
            <span class="pill">Agentic Validation</span>
            <span class="pill">Streamlit</span>
          </div>
        </div>

        <div class="blog-post__content">
          <section>
            <h2>Overview</h2>
            <p>
              Freight forwarding ops run on messy PDFs (often scans) and long email threads that mix multiple intents.
              I built a modular, end-to-end agentic pipeline that combines <strong>OCR-grounded document parsing</strong> with
              <strong>intent-aware email automation</strong>. The key idea is simple: treat every LLM output as a hypothesis that must be
              <strong>grounded in OCR evidence</strong> and <strong>validated by agents + deterministic checks</strong> before it can be used.
            </p>

            <ul>
              <li><strong>Workflow A (Document Intelligence):</strong> OCR → schema-constrained JSON → deterministic grounding → validation agent → visual audit</li>
              <li><strong>Workflow B (Communication Intelligence):</strong> thread parsing → turn segmentation → intent labeling → reply drafting → safety gating</li>
            </ul>

            <p>
              <strong>Tech stack:</strong> PaddleOCR, schema-enforced JSON extraction, string-alignment grounding,
              validation agents, BART-MNLI (zero-shot), GPT-based labeling/judging, Streamlit UI, MongoDB.
            </p>
          </section>

          <section>
            <h2>The Problem</h2>
            <p>
              Freight documents (BOLs, pre-alerts, arrival notices, invoices) are highly heterogeneous: variable layouts, stamps,
              handwritten notes, low-quality scans, and inconsistent key fields. Email workflows add additional complexity with
              multilingual threads and overlapping intents.
            </p>

            <p>Manual processing was:</p>
            <ul>
              <li><strong>Error-prone:</strong> inconsistent extraction / mislabeling across templates</li>
              <li><strong>Slow:</strong> required review for most cases</li>
              <li><strong>Hard to scale:</strong> volume spikes created operational bottlenecks</li>
            </ul>

            <p>
              The goal wasn’t “maximum automation.” It was <strong>safe automation</strong>—only auto-process when outputs are
              <strong>verifiable</strong>, otherwise escalate confidently.
            </p>
          </section>

          <section>
            <h2>Solution Architecture</h2>

            <h3>Workflow A: Document Intelligence</h3>
            <ol>
              <li>
                <strong>OCR extraction:</strong> PaddleOCR extracts text + bounding boxes + confidence scores.
                Tokens are grouped into stable spatial blocks for downstream grounding.
              </li>
              <li>
                <strong>Schema-constrained JSON parsing:</strong> an LLM extracts required fields into a strict schema
                (types/keys enforced to reduce structural hallucinations).
              </li>
              <li>
                <strong>Deterministic OCR grounding:</strong> map extracted JSON values back to OCR evidence using
                exact match → substring → partial token overlap.
              </li>
              <li>
                <strong>Validation agent:</strong> focus on high-risk identifiers (e.g., shipment numbers).
                Replace/repair fields only if an OCR-backed match exists (substring + edit-distance similarity).
              </li>
              <li>
                <strong>Storage + audit:</strong> store outputs + QA signals in MongoDB and expose a Streamlit visual reviewer.
              </li>
            </ol>

            <h3>Workflow B: Communication Intelligence</h3>
            <ol>
              <li>
                <strong>Email parsing + segmentation:</strong> convert <code>.eml</code> into structured turns,
                strip signatures/disclaimers, and split threads using robust reply separators (including multilingual).
              </li>
              <li>
                <strong>Intent labeling:</strong> classify segments into operational buckets (e.g., Pre-alert, Arrival Notice,
                Terminal Release, Trucking) using a blend of rules, zero-shot NLI, and LLM labeling with evidence quotes.
              </li>
              <li>
                <strong>Reply drafting + safety gating:</strong> generate replies from structured inputs and enforce constraints:
                do not introduce shipment IDs/dates/statuses/amounts unless present in the thread/document context.
              </li>
              <li>
                <strong>Independent judge:</strong> an LLM-as-a-judge evaluates completeness + tone + sendability,
                but deterministic checks override approval.
              </li>
            </ol>


            
            <figure>
              <img src="./assets/workflow_a.png" alt="Workflow A diagram" style="width:100%;border-radius:12px;">
              <figcaption>Workflow A: Document Intelligence</figcaption>
            </figure>
            <figure>
              <img src="./assets/workflow_b.png" alt="Workflow B diagram" style="width:100%;border-radius:12px;">
              <figcaption>Workflow B: Communication Intelligence</figcaption>
            </figure>
            
          </section>

          <section>
            <h2>Results</h2>

            <p>
              The biggest gains came from pairing <strong>schema constraints</strong> with <strong>deterministic grounding</strong>
              and a <strong>targeted validation agent</strong> for high-risk fields.
            </p>

            <table class="results-table">
              <tr>
                <th>Configuration</th>
                <th>Mislabel Rate</th>
                <th>CER</th>
              </tr>
              <tr>
                <td>Flexible prompt (no strict schema)</td>
                <td>14.2%</td>
                <td>9.5%</td>
              </tr>
              <tr>
                <td>Strict schema + alignment (no validation agent)</td>
                <td>5.4%</td>
                <td>4.8%</td>
              </tr>
              <tr>
                <td><strong>Strict schema + alignment + validation agent</strong></td>
                <td><strong>1.8%</strong></td>
                <td><strong>2.5%</strong></td>
              </tr>
            </table>

            <p>
              On the communication side, the system explicitly separates “safe to automate” from “needs review.”
              The pipeline produced three operational buckets:
            </p>
            <ul>
              <li><strong>Ready-to-send (≈70%):</strong> high confidence + passes deterministic constraints</li>
              <li><strong>Hallucination detected (≈8%):</strong> unsafe additions (IDs/dates/status/amount) or validation mismatch</li>
              <li><strong>Escalation needed (≈19%):</strong> ambiguous / multi-intent / missing information → human-in-the-loop</li>
            </ul>
          </section>

          <section>
            <h2>Key Technical Insights</h2>
            <ul>
              <li>
                <strong>Schema constraints matter:</strong> forcing a strict JSON contract reduces structural errors and makes validation easier.
              </li>
              <li>
                <strong>Grounding beats “LLM reasoning” over boxes:</strong> deterministic string alignment to OCR evidence was more reliable in practice.
              </li>
              <li>
                <strong>Agents should be narrow:</strong> validation agents focused on high-risk identifiers delivered the best ROI.
              </li>
              <li>
                <strong>Abstention is a feature:</strong> the escalation bucket is intentional—safety &gt; automation in ops workflows.
              </li>
              <li>
                <strong>Judge ≠ authority:</strong> the judge helps scale evaluation, but deterministic constraints must override.
              </li>
            </ul>
          </section>

          <section>
            <h2>Interactive Streamlit Viewer</h2>
            <p>
              To make verification fast, I built a Streamlit app that lets operators visually audit OCR and extracted fields.
            </p>

            <h3>Core Features</h3>
            <ul>
              <li><strong>Document browser:</strong> select processed docs from the pipeline</li>
              <li><strong>Rendered PDF/image viewer:</strong> view the original content in-browser</li>
              <li><strong>OCR overlay:</strong> hover to inspect extracted text + confidence (color-coded)</li>
              <li><strong>Parsed field overlay:</strong> show structured fields mapped back to document regions</li>
              <li><strong>JSON inspector:</strong> review the complete parsed JSON in the sidebar</li>
            </ul>

            <h3>Implementation Notes</h3>
            <ul>
              <li><strong>Streamlit:</strong> interactive UI scaffolding</li>
              <li><strong>PIL/Pillow:</strong> thumbnails + image transforms</li>
              <li><strong>Custom HTML/CSS overlays:</strong> hover tooltips + zoomed regions</li>
              <li><strong>Base64 images:</strong> efficient in-browser rendering</li>
            </ul>
          </section>

          <section>
            <h2>Takeaways</h2>
            <p>This project reinforced a practical recipe for agentic automation in high-stakes workflows:</p>
            <ul>
              <li>Combine multiple weak signals (OCR, LLM, rules) into a stronger system</li>
              <li>Force verifiability via grounding and schema contracts</li>
              <li>Make uncertainty explicit (abstain + escalate)</li>
              <li>Keep humans in the loop for ambiguous or high-impact cases</li>
              <li>Give operators tooling (visual audits) instead of blind trust</li>
            </ul>
          </section>
        </div>

        <div class="blog-nav">
          <a href="./blog-ssl.html" class="blog-nav__link">← Previous: Self-Supervised Learning</a>
          <a href="./index.html#projects" class="blog-nav__link">All Projects</a>
          <a href="./blog-recommender.html" class="blog-nav__link">Next: Movie Recommender →</a>
        </div>
      </article>
    </main>

    <footer class="site-footer">
      <span>© <span id="year"></span> Samarth Agarwal</span>
      <div class="footer__links">
        <a href="./index.html#top">Back to home</a>
      </div>
    </footer>
  </div>

  <script src="./scripts/main.js"></script>
</body>
</html>
